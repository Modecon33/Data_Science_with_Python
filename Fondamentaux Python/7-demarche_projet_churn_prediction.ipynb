{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPc3i0BgBXYwc7l7qj1iMjI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RbfMgvzkr4K2","executionInfo":{"status":"ok","timestamp":1745445979562,"user_tz":-120,"elapsed":18917,"user":{"displayName":"amebi data","userId":"11841339747529792789"}},"outputId":"71c04077-a475-4b16-db84-a26f2e3a3b0a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# ğŸ“Œ **Projet Machine Learning : Churn Prediction**\n","\n","## ğŸš€ **1. DÃ©finir un Objectif Mesurable**\n","Avant de commencer, il est essentiel de dÃ©finir un objectif clair et mesurable. Par exemple :\n","\n","ğŸ‘‰ **PrÃ©dire si une personne est susceptible de rÃ©silier son abonnement tÃ©lÃ©phonique avec une exactitude de 90%.**\n","\n","### ğŸ“Š **MÃ©trique principale : Accuracy > 90%**  \n","_Cela signifie que sur 100 prÃ©dictions, nous avons raison 90% du temps._\n","\n","\n","### âš ï¸ **ProblÃ¨me des Classes DÃ©sÃ©quilibrÃ©es**\n","Dans ce type de projet, les classes sont souvent dÃ©sÃ©quilibrÃ©es. Exemple :  \n","- **90%** des clients **ne rÃ©silient pas** leur abonnement (**classe 0**).  \n","- **10%** des clients **rÃ©silient** leur abonnement (**classe 1**).  \n","\n","ğŸ‘‰ Si l'on utilise uniquement **lâ€™accuracy**, on risque de biaiser lâ€™Ã©valuation. Il est donc prÃ©fÃ©rable dâ€™utiliser dâ€™autres mÃ©triques adaptÃ©es :\n","\n","- **ğŸ“Œ PrÃ©cision (Precision) :** RÃ©duit le nombre de **faux positifs**.  \n","  $$ \\text{Precision} = \\frac{TP}{TP + FP} $$\n","  _Cela permet d'Ã©viter de prÃ©dire qu'un client va rÃ©silier alors qu'il ne le fera pas._\n","\n","- **ğŸ“Œ Rappel (Recall / SensibilitÃ©) :** RÃ©duit le nombre de **faux nÃ©gatifs**.  \n","  $$ \\text{Recall} = \\frac{TP}{TP + FN} $$\n","  _Cela permet dâ€™Ã©viter de rater des clients susceptibles de rÃ©silier leur abonnement._\n","\n","- **ğŸ“Œ Score F1 :** Compromis entre prÃ©cision et rappel.  \n","  $$ \\text{F1-score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} $$\n","\n","### ğŸ¯ **Objectif fixÃ© :**  \n","âœ… **F1-score > 50%**  \n","âœ… **Recall > 70%** _(Si atteint, c'est dÃ©jÃ  une bonne performance !)_  \n","\n","---\n","\n","## ğŸ“Š **2. EDA (Exploratory Data Analysis)**  \n","ğŸ“Œ **Objectif :** Se familiariser avec les donnÃ©es pour Ã©tablir une stratÃ©gie de modÃ©lisation.\n","\n","### ğŸ” **Analyse de la Forme**  \n","âœ… Identification de la **variable cible** (*target*).  \n","âœ… Nombre de **lignes** et **colonnes**.  \n","âœ… Types de variables (**discrÃ¨tes, continues**).  \n","âœ… Identification des **valeurs manquantes**.  \n","\n","### ğŸ” **Analyse du Fond**  \n","âœ… **Visualisation de la cible** (histogrammes, boxplots).  \n","âœ… ComprÃ©hension des **relations entre features et target** :  \n","   - Variables **continue vs discrÃ¨te**  \n","   - Variables **continue vs continue**  \n","   - Variables **discrÃ¨te vs discrÃ¨te**  \n","âœ… Identification des **outliers** pour traitement lors du prÃ©-processing.\n","\n","---\n","\n","## ğŸ›  **3. Pre-processing : PrÃ©-traitement des DonnÃ©es**  \n","ğŸ“Œ **Objectif :** Transformer le dataset pour le rendre exploitable par un modÃ¨le de **Machine Learning**.\n","\n","### ğŸ”¹ **Ã‰tapes principales :**  \n","âœ… **CrÃ©ation du Train Set / Test Set**  \n","\n","âœ… **Gestion des valeurs manquantes**  \n","   - Suppression avec `dropna()`  \n","   - Imputation des valeurs manquantes (`SimpleImputer`)  \n","\n","âœ… **Encodage des variables catÃ©gorielles**  \n","   - **One-Hot Encoding**, **Ordinal Encoding**  \n","   - `replace()` ou `map()` de **pandas**  \n","\n","âœ… **Suppression des outliers**  \n","   - Identification des valeurs extrÃªmes  \n","   - VÃ©rification de leur impact sur le modÃ¨le  \n","\n","âœ… **Feature Selection (SÃ©lection de variables)**  \n","   - Suppression des variables avec **variance nulle**  \n","   - Ã‰limination des variables **redondantes**  \n","\n","âœ… **Feature Engineering**  \n","   - CrÃ©ation de **nouvelles variables pertinentes**  \n","   - Transformation **polynomiale** (`PolynomialFeatures`)  \n","   - RÃ©duction de **dimensionnalitÃ©** (`PCA`)  \n","\n","âœ… **Feature Scaling** (Mise Ã  lâ€™Ã©chelle des donnÃ©es)  \n","   - **Normalisation** (`MinMaxScaler`)  \n","   - **Standardisation** (`StandardScaler`)  \n","\n","---\n","\n","## ğŸ¤– **4. Modelling**  \n","ğŸ“Œ **Objectif :** Obtenir un modÃ¨le **fiable et reproductible**.\n","\n","### ğŸ”¹ **Ã‰tapes principales :**  \n","âœ… **CrÃ©ation d'un modÃ¨le ML conforme Ã  l'objectif.**  \n","âœ… **DÃ©finition d'une fonction d'Ã©valuation** (`accuracy`, `f1-score`, `recall`).  \n","âœ… **EntraÃ®nement de plusieurs modÃ¨les** (_RÃ©gression Logistique, Random Forest, XGBoost, etc._).  \n","âœ… **Optimisation avec `GridSearchCV` ou `RandomizedSearchCV`**.  \n","âœ… **Analyse des erreurs et retour au prÃ©-processing / EDA si nÃ©cessaire**.  \n","âœ… **Comparaison des modÃ¨les et prise de dÃ©cision via une **learning curve**.\n","\n","---\n","\n","## ğŸ“Œ **ğŸ“ˆ Conclusion**  \n","En suivant cette dÃ©marche, nous assurons :  \n","âœ… Une **analyse rigoureuse des donnÃ©es**  \n","âœ… Une **modÃ©lisation optimisÃ©e**  \n","âœ… Une **meilleure comprÃ©hension du churn client**  \n","\n","### ğŸ¯ **Objectif final :**  \n","ğŸ‘‰ **PrÃ©dire les clients susceptibles de rÃ©silier leur abonnement** et mettre en place des actions **prÃ©ventives**. ğŸš€"],"metadata":{"id":"QoLWTwr3rPKV"}}]}